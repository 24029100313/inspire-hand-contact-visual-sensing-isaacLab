#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆä¼ æ„Ÿå™¨ vs åŸºçº¿ç‰ˆæœ¬ RL æ€§èƒ½å¯¹æ¯”å®éªŒ

æ–°å¢åŠŸèƒ½ï¼š
- ğŸ¯ æˆåŠŸç‡ç»Ÿè®¡
- ğŸ“ å¼€å¯ç¨‹åº¦è®°å½• 
- ğŸ¬ å…³é”®ç¯èŠ‚è§†é¢‘è®°å½•
- ğŸ“ æ¯æ¬¡å®éªŒå»ºç«‹ç‰¹å®šçš„æ–‡ä»¶å¤¹
- ğŸ“Š è¯¦ç»†çš„æ€§èƒ½åˆ†æ

ç”¨æ³•:
    python enhanced_sensor_vs_baseline_experiment.py --num_envs 64 --max_iterations 100
"""

import argparse
import subprocess
import time
import os
import psutil
import threading
import json
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path
import numpy as np
import re


class ExperimentManager:
    """å®éªŒç®¡ç†å™¨ - è´Ÿè´£åˆ›å»ºå®éªŒæ–‡ä»¶å¤¹å’Œç»„ç»‡è¾“å‡º"""
    
    def __init__(self, base_name: str = "cabinet_experiment"):
        self.base_name = base_name
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.experiment_root = Path(f"experiments/{base_name}_{self.timestamp}")
        
        # åˆ›å»ºå®éªŒç›®å½•ç»“æ„
        self.experiment_root.mkdir(parents=True, exist_ok=True)
        
        # å­ç›®å½•
        self.baseline_dir = self.experiment_root / "baseline"
        self.sensor_dir = self.experiment_root / "sensor"
        self.videos_dir = self.experiment_root / "videos"
        self.logs_dir = self.experiment_root / "logs"
        self.results_dir = self.experiment_root / "results"
        
        # åˆ›å»ºæ‰€æœ‰å­ç›®å½•
        for dir_path in [self.baseline_dir, self.sensor_dir, self.videos_dir, 
                        self.logs_dir, self.results_dir]:
            dir_path.mkdir(exist_ok=True)
        
        print(f"[å®éªŒç®¡ç†] å®éªŒç›®å½•å·²åˆ›å»º: {self.experiment_root}")
        print(f"[å®éªŒç®¡ç†] ç›®å½•ç»“æ„:")
        print(f"â”œâ”€â”€ baseline/     (åŸºçº¿ç‰ˆæœ¬è¾“å‡º)")
        print(f"â”œâ”€â”€ sensor/       (ä¼ æ„Ÿå™¨ç‰ˆæœ¬è¾“å‡º)")
        print(f"â”œâ”€â”€ videos/       (å…³é”®ç¯èŠ‚è§†é¢‘)")
        print(f"â”œâ”€â”€ logs/         (è®­ç»ƒæ—¥å¿—)")
        print(f"â””â”€â”€ results/      (åˆ†æç»“æœ)")
    
    def get_experiment_path(self, version_type: str) -> Path:
        """è·å–ç‰¹å®šç‰ˆæœ¬çš„å®éªŒè·¯å¾„"""
        if version_type == "baseline":
            return self.baseline_dir
        elif version_type == "sensors":
            return self.sensor_dir
        else:
            raise ValueError(f"Unknown version type: {version_type}")
    
    def get_video_path(self, version_type: str, video_type: str) -> Path:
        """è·å–è§†é¢‘ä¿å­˜è·¯å¾„"""
        return self.videos_dir / f"{version_type}_{video_type}"
    
    def get_log_path(self, version_type: str) -> Path:
        """è·å–æ—¥å¿—ä¿å­˜è·¯å¾„"""
        return self.logs_dir / f"{version_type}_training.log"
    
    def get_results_path(self, filename: str) -> Path:
        """è·å–ç»“æœæ–‡ä»¶è·¯å¾„"""
        return self.results_dir / filename


class TaskAnalyzer:
    """ä»»åŠ¡åˆ†æå™¨ - ä¸“é—¨ç”¨äºåˆ†ææŠ½å±‰å¼€å¯ä»»åŠ¡"""
    
    def __init__(self):
        self.success_episodes = []
        self.failure_episodes = []
        self.opening_progress = []
        self.episode_rewards = []
        self.episode_lengths = []
        self.contact_events = []
        
        # æˆåŠŸæ ‡å‡†
        self.success_threshold = 0.25  # æŠ½å±‰å¼€å¯è·ç¦»é˜ˆå€¼ï¼ˆç±³ï¼‰
        self.reward_threshold = 50.0   # å¥–åŠ±é˜ˆå€¼
        
    def parse_episode_from_log(self, log_line: str) -> Optional[Dict]:
        """ä»æ—¥å¿—è¡Œä¸­è§£æepisodeä¿¡æ¯"""
        try:
            # è§£ææˆåŠŸçš„episode
            if "episode" in log_line.lower() and "reward" in log_line.lower():
                # æå–episodeä¿¡æ¯
                episode_match = re.search(r'episode[:\s]*(\d+)', log_line.lower())
                reward_match = re.search(r'reward[:\s]*([+-]?\d+\.?\d*)', log_line.lower())
                
                if episode_match and reward_match:
                    episode_id = int(episode_match.group(1))
                    total_reward = float(reward_match.group(1))
                    
                    # ä¼°ç®—å¼€å¯è·ç¦»ï¼ˆåŸºäºå¥–åŠ±ï¼‰
                    estimated_opening = max(0, (total_reward - 10) / 100)  # ç®€åŒ–ä¼°ç®—
                    
                    return {
                        'episode_id': episode_id,
                        'total_reward': total_reward,
                        'estimated_opening': estimated_opening,
                        'is_success': total_reward > self.reward_threshold
                    }
            
            return None
            
        except Exception:
            return None
    
    def analyze_training_log(self, log_path: Path):
        """åˆ†æè®­ç»ƒæ—¥å¿—"""
        if not log_path.exists():
            return
        
        with open(log_path, 'r', encoding='utf-8') as f:
            for line in f:
                episode_data = self.parse_episode_from_log(line)
                if episode_data:
                    self.episode_rewards.append(episode_data['total_reward'])
                    self.opening_progress.append(episode_data['estimated_opening'])
                    
                    if episode_data['is_success']:
                        self.success_episodes.append(episode_data)
                    else:
                        self.failure_episodes.append(episode_data)
    
    def get_success_rate(self) -> float:
        """è·å–æˆåŠŸç‡"""
        total_episodes = len(self.success_episodes) + len(self.failure_episodes)
        if total_episodes == 0:
            return 0.0
        return len(self.success_episodes) / total_episodes
    
    def get_average_opening_distance(self) -> float:
        """è·å–å¹³å‡å¼€å¯è·ç¦»"""
        if not self.opening_progress:
            return 0.0
        return np.mean(self.opening_progress)
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–ä»»åŠ¡åˆ†ææ‘˜è¦"""
        total_episodes = len(self.success_episodes) + len(self.failure_episodes)
        
        if total_episodes == 0:
            return {
                'total_episodes': 0,
                'success_rate': 0.0,
                'average_opening_distance': 0.0,
                'average_episode_reward': 0.0,
                'max_opening_distance': 0.0,
                'successful_episodes': 0,
                'failed_episodes': 0
            }
        
        return {
            'total_episodes': total_episodes,
            'successful_episodes': len(self.success_episodes),
            'failed_episodes': len(self.failure_episodes),
            'success_rate': self.get_success_rate(),
            'average_opening_distance': self.get_average_opening_distance(),
            'max_opening_distance': np.max(self.opening_progress) if self.opening_progress else 0.0,
            'average_episode_reward': np.mean(self.episode_rewards) if self.episode_rewards else 0.0,
            'reward_std': np.std(self.episode_rewards) if self.episode_rewards else 0.0,
            'opening_distance_std': np.std(self.opening_progress) if self.opening_progress else 0.0,
        }


class PerformanceMonitor:
    """ç³»ç»Ÿæ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.monitoring = False
        self.cpu_samples = []
        self.gpu_memory_samples = []
        self.system_memory_samples = []
        self.monitor_thread = None
        self.start_time = None
    
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        self.monitoring = True
        self.start_time = time.time()
        self.monitor_thread = threading.Thread(target=self._monitor_loop)
        self.monitor_thread.daemon = True
        self.monitor_thread.start()
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=2.0)
    
    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.monitoring:
            try:
                # CPUä½¿ç”¨ç‡
                cpu_percent = psutil.cpu_percent()
                self.cpu_samples.append(cpu_percent)
                
                # ç³»ç»Ÿå†…å­˜ä½¿ç”¨ç‡
                memory = psutil.virtual_memory()
                self.system_memory_samples.append(memory.percent)
                
                # GPUç›‘æ§ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                try:
                    import pynvml
                    pynvml.nvmlInit()
                    handle = pynvml.nvmlDeviceGetHandleByIndex(0)
                    memory_info = pynvml.nvmlDeviceGetMemoryInfo(handle)
                    gpu_memory_gb = memory_info.used / (1024 ** 3)
                    self.gpu_memory_samples.append(gpu_memory_gb)
                except:
                    self.gpu_memory_samples.append(0.0)
                
                time.sleep(2.0)
                
            except Exception:
                continue
    
    def get_summary(self) -> Dict[str, float]:
        """è·å–ç›‘æ§æ‘˜è¦"""
        if not self.cpu_samples:
            return {}
        
        return {
            'avg_cpu_percent': np.mean(self.cpu_samples),
            'max_cpu_percent': np.max(self.cpu_samples),
            'avg_system_memory_percent': np.mean(self.system_memory_samples),
            'avg_gpu_memory_gb': np.mean(self.gpu_memory_samples) if self.gpu_memory_samples else 0.0,
            'max_gpu_memory_gb': np.max(self.gpu_memory_samples) if self.gpu_memory_samples else 0.0,
        }


def parse_training_output(line: str) -> Optional[Dict]:
    """è§£æè®­ç»ƒè¾“å‡º"""
    result = {}
    
    try:
        # è§£æè¿­ä»£ä¿¡æ¯
        if "it/" in line.lower():
            it_match = re.search(r'it/(\d+)', line.lower())
            if it_match:
                result['iteration'] = int(it_match.group(1))
        
        # è§£æå¥–åŠ±ä¿¡æ¯
        reward_match = re.search(r'reward[:\s]*([+-]?\d+\.?\d*)', line.lower())
        if reward_match:
            result['reward'] = float(reward_match.group(1))
        
        # è§£æFPSä¿¡æ¯
        fps_match = re.search(r'(\d+\.?\d*)\s*fps', line.lower())
        if fps_match:
            result['fps'] = float(fps_match.group(1))
        
        return result if result else None
        
    except Exception:
        return None


def run_enhanced_experiment(version_type: str, num_envs: int, max_iterations: int, 
                           seed: int, experiment_manager: ExperimentManager) -> Dict[str, Any]:
    """è¿è¡Œå¢å¼ºç‰ˆå®éªŒ"""
    
    # ç¡®å®šä½¿ç”¨çš„è„šæœ¬
    if version_type == "baseline":
        script = "cabinet_rl_BASELINE.py"
        name = "åŸºçº¿ç‰ˆæœ¬ï¼ˆæ— ä¼ æ„Ÿå™¨ï¼‰"
    elif version_type == "sensors":
        script = "cabinet_rl_WITH_SENSORS.py"
        name = "ä¼ æ„Ÿå™¨ç‰ˆæœ¬"
    else:
        raise ValueError(f"Unknown version type: {version_type}")
    
    print(f"\n{'='*70}")
    print(f"   ğŸš€ å¼€å§‹å¢å¼ºå®éªŒ: {name}")
    print(f"   ğŸŒ ç¯å¢ƒæ•°: {num_envs}")
    print(f"   ğŸ“Š æœ€å¤§è¿­ä»£: {max_iterations}")
    print(f"   ğŸ² éšæœºç§å­: {seed}")
    print(f"   ğŸ• å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
    print(f"{'='*70}")
    
    # è·å–å®éªŒè·¯å¾„
    experiment_path = experiment_manager.get_experiment_path(version_type)
    log_path = experiment_manager.get_log_path(version_type)
    
    # å¯åŠ¨æ€§èƒ½ç›‘æ§
    monitor = PerformanceMonitor()
    monitor.start_monitoring()
    
    # æ„å»ºå‘½ä»¤ï¼Œæ·»åŠ è§†é¢‘å½•åˆ¶
    video_dir = experiment_manager.get_video_path(version_type, "training")
    video_dir.mkdir(exist_ok=True)
    
    cmd = [
        "./isaaclab.sh", "-p", script,
        "--num_envs", str(num_envs),
        "--max_iterations", str(max_iterations),
        "--seed", str(seed),
        "--video",  # å¯ç”¨è§†é¢‘å½•åˆ¶
        "--video_length", "200",  # è§†é¢‘é•¿åº¦
        "--video_interval", "500",  # å½•åˆ¶é—´éš”
        "--headless"
    ]
    
    print(f"ğŸ“¹ è§†é¢‘å½•åˆ¶å·²å¯ç”¨: {video_dir}")
    print(f"ğŸ“Š æ€§èƒ½ç›‘æ§å·²å¯åŠ¨")
    
    start_time = time.time()
    training_results = {
        'final_reward': 0.0,
        'final_steps_per_sec': 0.0,
        'total_steps': 0,
        'reward_history': [],
        'iteration_history': [],
        'fps_history': [],
        'max_reward_achieved': -float('inf'),
        'min_reward_achieved': float('inf')
    }
    
    # ä¿å­˜è®­ç»ƒæ—¥å¿—
    log_file = open(log_path, 'w', encoding='utf-8')
    log_file.write(f"å®éªŒå¼€å§‹: {datetime.now().isoformat()}\n")
    log_file.write(f"é…ç½®: {version_type}, {num_envs} envs, {max_iterations} iters, seed {seed}\n")
    log_file.write("-" * 50 + "\n")
    
    try:
        # å¯åŠ¨è®­ç»ƒè¿›ç¨‹
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
            universal_newlines=True
        )
        
        print("ğŸ“Š å®æ—¶ç›‘æ§è®­ç»ƒè¿›åº¦:")
        print("   æ ¼å¼: [æ—¶é—´] è¿­ä»£ | å¥–åŠ± | æ­¥æ•°/ç§’")
        print("-" * 60)
        
        iteration_count = 0
        last_reward = 0.0
        last_fps = 0.0
        last_progress_time = time.time()
        timeout_duration = 3600  # 60åˆ†é’Ÿè¶…æ—¶
        
        # å®æ—¶è¯»å–è¾“å‡º
        for line in iter(process.stdout.readline, ''):
            if not line:
                break
                
            line = line.strip()
            current_time = datetime.now().strftime('%H:%M:%S')
            
            # ä¿å­˜åˆ°æ—¥å¿—æ–‡ä»¶
            log_file.write(f"[{current_time}] {line}\n")
            log_file.flush()
            
            # è§£æè®­ç»ƒä¿¡æ¯
            parsed_info = parse_training_output(line)
            if parsed_info:
                if 'iteration' in parsed_info:
                    iteration_count = parsed_info['iteration']
                    last_progress_time = time.time()
                
                if 'reward' in parsed_info:
                    last_reward = parsed_info['reward']
                    training_results['reward_history'].append(last_reward)
                    training_results['iteration_history'].append(iteration_count)
                    
                    # æ›´æ–°æœ€å¤§æœ€å°å¥–åŠ±
                    training_results['max_reward_achieved'] = max(
                        training_results['max_reward_achieved'], last_reward
                    )
                    training_results['min_reward_achieved'] = min(
                        training_results['min_reward_achieved'], last_reward
                    )
                
                if 'fps' in parsed_info:
                    last_fps = parsed_info['fps']
                    training_results['fps_history'].append(last_fps)
            
            # æ˜¾ç¤ºè¿›åº¦ï¼ˆæ¯10ä¸ªè¿­ä»£æ˜¾ç¤ºä¸€æ¬¡ï¼‰
            if iteration_count > 0 and iteration_count % 10 == 0:
                print(f"[{current_time}] è¿­ä»£ {iteration_count:3d} | "
                      f"å¥–åŠ± {last_reward:6.2f} | "
                      f"FPS {last_fps:4.0f}")
            
            # æ£€æŸ¥è¶…æ—¶
            if time.time() - last_progress_time > timeout_duration:
                print(f"âš ï¸ è­¦å‘Š: {timeout_duration}ç§’å†…æ— è¿›å±•ï¼Œç»ˆæ­¢è¿›ç¨‹")
                process.kill()
                break
        
        # ç­‰å¾…è¿›ç¨‹å®Œæˆ
        process.wait()
        
    except Exception as e:
        print(f"âŒ å®éªŒæ‰§è¡Œé”™è¯¯: {e}")
        log_file.write(f"é”™è¯¯: {e}\n")
    
    finally:
        log_file.close()
        monitor.stop_monitoring()
    
    # åˆ†æä»»åŠ¡æ€§èƒ½
    task_analyzer = TaskAnalyzer()
    task_analyzer.analyze_training_log(log_path)
    
    # å®Œæˆè®­ç»ƒç»“æœ
    total_duration = time.time() - start_time
    training_results['final_reward'] = last_reward
    training_results['final_steps_per_sec'] = last_fps
    training_results['total_steps'] = iteration_count * num_envs
    
    # è·å–æ€§èƒ½æ‘˜è¦
    performance_summary = monitor.get_summary()
    
    # è·å–ä»»åŠ¡åˆ†ææ‘˜è¦
    task_summary = task_analyzer.get_summary()
    
    # æ„å»ºå®Œæ•´ç»“æœ
    result = {
        'version': version_type,
        'name': name,
        'duration_min': total_duration / 60,
        'training_results': training_results,
        'performance': performance_summary,
        'task_analysis': task_summary,
        'config': {
            'num_envs': num_envs,
            'max_iterations': max_iterations,
            'seed': seed
        },
        'paths': {
            'experiment_dir': str(experiment_path),
            'log_file': str(log_path),
            'video_dir': str(video_dir)
        }
    }
    
    # æ˜¾ç¤ºç»“æœæ‘˜è¦
    print(f"\nâœ… {name} å®éªŒå®Œæˆ!")
    print(f"   â±ï¸ æ€»ç”¨æ—¶: {total_duration/60:.1f} åˆ†é’Ÿ")
    print(f"   ğŸ¯ æœ€ç»ˆå¥–åŠ±: {training_results['final_reward']:.2f}")
    print(f"   ğŸš€ æœ€ç»ˆFPS: {training_results['final_steps_per_sec']:.0f}")
    print(f"   ğŸ“Š æˆåŠŸç‡: {task_summary['success_rate']:.1%}")
    print(f"   ğŸ“ å¹³å‡å¼€å¯è·ç¦»: {task_summary['average_opening_distance']:.3f}m")
    print(f"   ğŸ’» å¹³å‡CPU: {performance_summary.get('avg_cpu_percent', 0):.1f}%")
    print(f"   ğŸ® å¹³å‡GPUå†…å­˜: {performance_summary.get('avg_gpu_memory_gb', 0):.1f}GB")
    
    return result


def compare_enhanced_results(baseline_result: Dict, sensor_result: Dict):
    """å¯¹æ¯”åˆ†æå¢å¼ºå®éªŒç»“æœ"""
    
    print(f"\n{'='*70}")
    print(" ğŸ“Š å¢å¼ºå®éªŒç»“æœå¯¹æ¯”åˆ†æ")
    print(f"{'='*70}")
    
    # åŸºæœ¬ä¿¡æ¯
    print("\nğŸ“‹ å®éªŒé…ç½®:")
    print(f"â”œâ”€â”€ ç¯å¢ƒæ•°: {baseline_result['config']['num_envs']}")
    print(f"â”œâ”€â”€ æœ€å¤§è¿­ä»£: {baseline_result['config']['max_iterations']}")
    print(f"â””â”€â”€ éšæœºç§å­: {baseline_result['config']['seed']}")
    
    # ä»»åŠ¡æ€§èƒ½å¯¹æ¯”
    print("\nğŸ¯ ä»»åŠ¡æ€§èƒ½å¯¹æ¯”:")
    baseline_task = baseline_result['task_analysis']
    sensor_task = sensor_result['task_analysis']
    
    # æˆåŠŸç‡å¯¹æ¯”
    success_rate_diff = sensor_task['success_rate'] - baseline_task['success_rate']
    print(f"â”œâ”€â”€ æˆåŠŸç‡:")
    print(f"â”‚   â”œâ”€â”€ åŸºçº¿ç‰ˆæœ¬: {baseline_task['success_rate']:.1%}")
    print(f"â”‚   â”œâ”€â”€ ä¼ æ„Ÿå™¨ç‰ˆæœ¬: {sensor_task['success_rate']:.1%}")
    print(f"â”‚   â””â”€â”€ å·®å¼‚: {success_rate_diff:+.1%}")
    
    # å¼€å¯è·ç¦»å¯¹æ¯”
    opening_diff = sensor_task['average_opening_distance'] - baseline_task['average_opening_distance']
    print(f"â”œâ”€â”€ å¹³å‡å¼€å¯è·ç¦»:")
    print(f"â”‚   â”œâ”€â”€ åŸºçº¿ç‰ˆæœ¬: {baseline_task['average_opening_distance']:.3f}m")
    print(f"â”‚   â”œâ”€â”€ ä¼ æ„Ÿå™¨ç‰ˆæœ¬: {sensor_task['average_opening_distance']:.3f}m")
    print(f"â”‚   â””â”€â”€ å·®å¼‚: {opening_diff:+.3f}m")
    
    # å¥–åŠ±å¯¹æ¯”
    baseline_training = baseline_result['training_results']
    sensor_training = sensor_result['training_results']
    
    reward_diff = sensor_training['final_reward'] - baseline_training['final_reward']
    reward_diff_pct = (reward_diff / baseline_training['final_reward']) * 100 if baseline_training['final_reward'] != 0 else 0
    
    print(f"â””â”€â”€ æœ€ç»ˆå¥–åŠ±:")
    print(f"    â”œâ”€â”€ åŸºçº¿ç‰ˆæœ¬: {baseline_training['final_reward']:.3f}")
    print(f"    â”œâ”€â”€ ä¼ æ„Ÿå™¨ç‰ˆæœ¬: {sensor_training['final_reward']:.3f}")
    print(f"    â””â”€â”€ å·®å¼‚: {reward_diff:+.3f} ({reward_diff_pct:+.1f}%)")
    
    # ç»¼åˆç»“è®º
    print("\nğŸ“ˆ ç»¼åˆç»“è®º:")
    
    if success_rate_diff > 0.1:
        task_conclusion = "âœ… ä¼ æ„Ÿå™¨æ˜¾è‘—æé«˜äº†ä»»åŠ¡æˆåŠŸç‡"
    elif success_rate_diff > 0.05:
        task_conclusion = "âœ… ä¼ æ„Ÿå™¨è½»å¾®æé«˜äº†ä»»åŠ¡æˆåŠŸç‡"
    elif success_rate_diff > -0.05:
        task_conclusion = "â– ä¼ æ„Ÿå™¨å¯¹ä»»åŠ¡æˆåŠŸç‡å½±å“å¾ˆå°"
    else:
        task_conclusion = "âŒ ä¼ æ„Ÿå™¨é™ä½äº†ä»»åŠ¡æˆåŠŸç‡"
    
    print(f"â””â”€â”€ ä»»åŠ¡æ€§èƒ½: {task_conclusion}")


def save_enhanced_results(baseline_result: Dict, sensor_result: Dict, 
                         experiment_manager: ExperimentManager):
    """ä¿å­˜å¢å¼ºå®éªŒç»“æœ"""
    
    # ä¸»è¦ç»“æœæ–‡ä»¶
    results_file = experiment_manager.get_results_path("experiment_results.json")
    
    # æ„å»ºå®Œæ•´ç»“æœ
    enhanced_results = {
        'experiment_info': {
            'timestamp': datetime.now().isoformat(),
            'description': 'å¢å¼ºç‰ˆä¼ æ„Ÿå™¨vsåŸºçº¿ç‰ˆæœ¬RLæ€§èƒ½å¯¹æ¯”å®éªŒ',
            'features': [
                'æˆåŠŸç‡ç»Ÿè®¡',
                'å¼€å¯ç¨‹åº¦è®°å½•',
                'å…³é”®ç¯èŠ‚è§†é¢‘è®°å½•',
                'è¯¦ç»†æ€§èƒ½åˆ†æ',
                'ç‹¬ç«‹å®éªŒæ–‡ä»¶å¤¹'
            ]
        },
        'baseline_result': baseline_result,
        'sensor_result': sensor_result,
        'comparison': {
            'success_rate_difference': (sensor_result['task_analysis']['success_rate'] - 
                                      baseline_result['task_analysis']['success_rate']),
            'opening_distance_difference': (sensor_result['task_analysis']['average_opening_distance'] - 
                                          baseline_result['task_analysis']['average_opening_distance']),
            'reward_difference_pct': ((sensor_result['training_results']['final_reward'] - 
                                     baseline_result['training_results']['final_reward']) / 
                                    baseline_result['training_results']['final_reward'] * 100) if baseline_result['training_results']['final_reward'] != 0 else 0
        },
        'experiment_paths': {
            'experiment_root': str(experiment_manager.experiment_root),
            'baseline_dir': str(experiment_manager.baseline_dir),
            'sensor_dir': str(experiment_manager.sensor_dir),
            'videos_dir': str(experiment_manager.videos_dir),
            'logs_dir': str(experiment_manager.logs_dir),
            'results_dir': str(experiment_manager.results_dir)
        }
    }
    
    # ä¿å­˜ç»“æœ
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(enhanced_results, f, indent=2, ensure_ascii=False)
    
    # ä¿å­˜ç®€åŒ–æ‘˜è¦
    summary_file = experiment_manager.get_results_path("experiment_summary.json")
    summary = {
        'timestamp': enhanced_results['experiment_info']['timestamp'],
        'baseline_success_rate': baseline_result['task_analysis']['success_rate'],
        'sensor_success_rate': sensor_result['task_analysis']['success_rate'],
        'success_rate_improvement': enhanced_results['comparison']['success_rate_difference'],
        'baseline_opening_distance': baseline_result['task_analysis']['average_opening_distance'],
        'sensor_opening_distance': sensor_result['task_analysis']['average_opening_distance'],
        'opening_distance_improvement': enhanced_results['comparison']['opening_distance_difference'],
        'reward_improvement_pct': enhanced_results['comparison']['reward_difference_pct'],
        'experiment_root': str(experiment_manager.experiment_root)
    }
    
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ å®éªŒç»“æœå·²ä¿å­˜:")
    print(f"â”œâ”€â”€ è¯¦ç»†ç»“æœ: {results_file}")
    print(f"â””â”€â”€ æ‘˜è¦ç»“æœ: {summary_file}")


def main():
    parser = argparse.ArgumentParser(description="å¢å¼ºç‰ˆä¼ æ„Ÿå™¨vsåŸºçº¿ç‰ˆæœ¬RLæ€§èƒ½å¯¹æ¯”å®éªŒ")
    parser.add_argument("--num_envs", type=int, default=64, help="å¹¶è¡Œç¯å¢ƒæ•°")
    parser.add_argument("--max_iterations", type=int, default=100, help="æœ€å¤§è®­ç»ƒè¿­ä»£æ•°")
    parser.add_argument("--seed", type=int, default=42, help="éšæœºç§å­")
    parser.add_argument("--experiment_name", type=str, default="cabinet_sensor_comparison", 
                       help="å®éªŒåç§°")
    
    args = parser.parse_args()
    
    # åˆ›å»ºå®éªŒç®¡ç†å™¨
    experiment_manager = ExperimentManager(args.experiment_name)
    
    print("ğŸ”¬ å¢å¼ºç‰ˆä¼ æ„Ÿå™¨ vs åŸºçº¿ç‰ˆæœ¬ RL æ€§èƒ½å¯¹æ¯”å®éªŒ")
    print("=" * 70)
    print(f"å®éªŒé…ç½®:")
    print(f"â”œâ”€â”€ å¹¶è¡Œç¯å¢ƒæ•°: {args.num_envs}")
    print(f"â”œâ”€â”€ æœ€å¤§è¿­ä»£æ•°: {args.max_iterations}")
    print(f"â”œâ”€â”€ éšæœºç§å­: {args.seed}")
    print(f"â”œâ”€â”€ å®éªŒåç§°: {args.experiment_name}")
    print(f"â””â”€â”€ å®éªŒç›®å½•: {experiment_manager.experiment_root}")
    
    print(f"\nğŸ¯ æ–°å¢åŠŸèƒ½:")
    print(f"â”œâ”€â”€ âœ… æˆåŠŸç‡ç»Ÿè®¡")
    print(f"â”œâ”€â”€ ğŸ“ å¼€å¯ç¨‹åº¦è®°å½•")
    print(f"â”œâ”€â”€ ğŸ¬ å…³é”®ç¯èŠ‚è§†é¢‘è®°å½•")
    print(f"â”œâ”€â”€ ğŸ“ ç‹¬ç«‹å®éªŒæ–‡ä»¶å¤¹")
    print(f"â””â”€â”€ ğŸ“Š è¯¦ç»†æ€§èƒ½åˆ†æ")
    
    # è¿è¡ŒåŸºçº¿å®éªŒ
    print(f"\nğŸš€ ç¬¬ä¸€é˜¶æ®µ: åŸºçº¿ç‰ˆæœ¬å®éªŒ")
    baseline_result = run_enhanced_experiment("baseline", args.num_envs, 
                                            args.max_iterations, args.seed, 
                                            experiment_manager)
    
    # ç­‰å¾…ç³»ç»Ÿæ¢å¤
    print("\nâ³ ç­‰å¾…ç³»ç»Ÿæ¢å¤...")
    time.sleep(10)
    
    # è¿è¡Œä¼ æ„Ÿå™¨å®éªŒ
    print(f"\nğŸš€ ç¬¬äºŒé˜¶æ®µ: ä¼ æ„Ÿå™¨ç‰ˆæœ¬å®éªŒ")
    sensor_result = run_enhanced_experiment("sensors", args.num_envs, 
                                          args.max_iterations, args.seed, 
                                          experiment_manager)
    
    # å¯¹æ¯”åˆ†æç»“æœ
    compare_enhanced_results(baseline_result, sensor_result)
    
    # ä¿å­˜ç»“æœ
    save_enhanced_results(baseline_result, sensor_result, experiment_manager)
    
    print(f"\nğŸ‰ å®éªŒå®Œæˆï¼")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {experiment_manager.experiment_root}")
    print(f"ğŸ¬ è§†é¢‘æ–‡ä»¶ä½äº: {experiment_manager.videos_dir}")
    print(f"ğŸ“‹ æ—¥å¿—æ–‡ä»¶ä½äº: {experiment_manager.logs_dir}")
    print(f"ğŸ“Š åˆ†æç»“æœä½äº: {experiment_manager.results_dir}")


if __name__ == "__main__":
    main()
